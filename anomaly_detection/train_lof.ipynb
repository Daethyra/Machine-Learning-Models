{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Generate Synthetic Data\n",
    "We'll use the same approach as before but adapt it for the LOF model.\n",
    "\n",
    "Generate Synthetic Data: Create realistic synthetic data for normal and anomalous outbound connections.\n",
    "Feature Engineering: Transform the raw data into features suitable for the LOF model.\n",
    "Model Training: Train the LOF model on the synthetic data.\n",
    "Real-Time Monitoring: Use the trained model to predict anomalies in real-time.\n",
    "Let's start by generating the synthetic data and then proceed with the rest of the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       pid         process_name         src_ip  src_port       dst_ip  \\\n",
      "2045  3142  unknown_process.exe  192.168.1.100     61881  203.0.113.1   \n",
      "2046  3447  unknown_process.exe  192.168.1.100     60943  203.0.113.1   \n",
      "2047  2024  unknown_process.exe  192.168.1.100      4797  203.0.113.1   \n",
      "2048  1848  unknown_process.exe  192.168.1.100     63360  203.0.113.1   \n",
      "2049  1622  unknown_process.exe  192.168.1.100     30822  203.0.113.1   \n",
      "\n",
      "      dst_port   duration    bytes_sent  bytes_received           timestamp  \n",
      "2045      9102   8.509564   6131.851638     3244.091242 2023-01-01 06:51:00  \n",
      "2046     30713   3.306930    807.715203     1567.584315 2023-01-01 11:49:00  \n",
      "2047     25956  19.410234  11854.694766    14613.909998 2023-01-01 15:53:00  \n",
      "2048     21511  17.285092   7024.754290    21673.886764 2023-01-01 01:13:00  \n",
      "2049     61262   7.473897  11343.226504     3371.332004 2023-01-01 22:16:00  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define process rules for normal and anomalous behavior\n",
    "process_rules_normal = {\n",
    "    'chrome.exe': ['151.101.1.69', '172.217.16.195'],\n",
    "    'firefox.exe': ['151.101.1.69', '172.217.16.195'],\n",
    "    'svchost.exe': ['93.184.216.34'],\n",
    "    'explorer.exe': ['172.217.16.195']\n",
    "}\n",
    "\n",
    "process_rules_anomalous = {\n",
    "    'svchost.exe': ['198.51.100.2'],  # Legitimate process, unusual destination\n",
    "    'unknown_process.exe': ['203.0.113.1'],  # Unrecognized process\n",
    "}\n",
    "\n",
    "def generate_connections(process_rules, n, anomalous=False):\n",
    "    data = {'pid': [], 'process_name': [], 'src_ip': [], 'src_port': [], 'dst_ip': [],\n",
    "            'dst_port': [], 'duration': [], 'bytes_sent': [], 'bytes_received': [], 'timestamp': []}\n",
    "\n",
    "    for process_name, dst_ips in process_rules.items():\n",
    "        for _ in range(n):\n",
    "            data['pid'].append(np.random.randint(1000, 5000))\n",
    "            data['process_name'].append(process_name)\n",
    "            data['src_ip'].append('192.168.1.100')\n",
    "            data['src_port'].append(np.random.randint(1024, 65535))\n",
    "            data['dst_ip'].append(np.random.choice(dst_ips))\n",
    "            data['dst_port'].append(np.random.randint(80, 443) if not anomalous else np.random.randint(1000, 65535))\n",
    "            data['duration'].append(np.random.exponential(scale=1.0) if not anomalous else np.random.exponential(scale=10.0))\n",
    "            data['bytes_sent'].append(np.random.exponential(scale=500) if not anomalous else np.random.exponential(scale=10000))\n",
    "            data['bytes_received'].append(np.random.exponential(scale=500) if not anomalous else np.random.exponential(scale=10000))\n",
    "            data['timestamp'].append(pd.Timestamp('2023-01-01') + pd.Timedelta(minutes=np.random.randint(0, 1440)))\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Generate normal connections\n",
    "df_normal = generate_connections(process_rules_normal, 500)\n",
    "\n",
    "# Generate anomalous connections with varied characteristics\n",
    "df_anomalous_legit = generate_connections({'svchost.exe': ['198.51.100.2']}, 20, anomalous=True)\n",
    "df_anomalous_unknown = generate_connections({'unknown_process.exe': ['203.0.113.1']}, 30, anomalous=True)\n",
    "\n",
    "# Combine the data\n",
    "df = pd.concat([df_normal, df_anomalous_legit, df_anomalous_unknown], ignore_index=True)\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Feature Engineering\n",
    "We'll preprocess the data to make it suitable for the LOF model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define the feature columns\n",
    "numeric_features = ['src_port', 'dst_port', 'duration', 'bytes_sent', 'bytes_received']\n",
    "categorical_features = ['process_name', 'dst_ip']\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Apply the preprocessing pipeline\n",
    "X = preprocessor.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Model Training\n",
    "Train the LOF model on the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of anomalies detected: 205\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# Initialize the Local Outlier Factor model\n",
    "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
    "\n",
    "# Fit the model to the preprocessed data and predict\n",
    "y_pred = lof.fit_predict(X)\n",
    "X_scores = lof.negative_outlier_factor_\n",
    "\n",
    "# Count the number of errors (anomalies detected)\n",
    "n_errors = (y_pred == -1).sum()\n",
    "print(f\"Number of anomalies detected: {n_errors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Real-Time Monitoring\n",
    "Use the trained model to predict anomalies in real-time. Note that LOF does not have predict, decision_function, or score_samples methods when used for outlier detection, so we'll need to fit the model again on the combined dataset including the new data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly\n"
     ]
    }
   ],
   "source": [
    "# Example new data point representing an anomalous outbound connection\n",
    "anomalous_new_data = {\n",
    "    'pid': [4100],  # Random PID within normal range\n",
    "    'process_name': ['unknown_process.exe'],  # Anomalous process\n",
    "    'src_ip': ['192.168.1.100'],  # Source IP (system IP)\n",
    "    'src_port': [5555],  # Unusual source port\n",
    "    'dst_ip': ['203.0.113.1'],  # Anomalous destination IP\n",
    "    'dst_port': [12345],  # Unusual destination port\n",
    "    'duration': [15.0],  # Longer than usual duration\n",
    "    'bytes_sent': [50000],  # Large amount of data sent\n",
    "    'bytes_received': [20000],  # Large amount of data received\n",
    "    'timestamp': [pd.Timestamp('2023-01-01 12:00:00')]  # Normal timestamp\n",
    "}\n",
    "\n",
    "new_df_anomalous = pd.DataFrame(anomalous_new_data)\n",
    "\n",
    "# Combine the new data point with the existing data\n",
    "df_combined = pd.concat([df, new_df_anomalous], ignore_index=True)\n",
    "\n",
    "# Preprocess the combined data\n",
    "X_combined = preprocessor.transform(df_combined)\n",
    "\n",
    "# Fit the LOF model to the combined data and predict\n",
    "y_pred_combined = lof.fit_predict(X_combined)\n",
    "new_data_prediction = y_pred_combined[-1]\n",
    "\n",
    "# Output the result\n",
    "print('Anomaly' if new_data_prediction == -1 else 'Normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly\n"
     ]
    }
   ],
   "source": [
    "# Example new data point representing an ambiguous outbound connection\n",
    "ambiguous_new_data = {\n",
    "    'pid': [2500],  # Random PID within normal range\n",
    "    'process_name': ['svchost.exe'],  # Known process\n",
    "    'src_ip': ['192.168.1.100'],  # Source IP (system IP)\n",
    "    'src_port': [8080],  # Normal source port\n",
    "    'dst_ip': ['198.51.100.2'],  # Unusual destination IP for svchost.exe\n",
    "    'dst_port': [80],  # Standard HTTP port\n",
    "    'duration': [2.0],  # Normal duration\n",
    "    'bytes_sent': [1000],  # Normal data sent\n",
    "    'bytes_received': [1500],  # Normal data received\n",
    "    'timestamp': [pd.Timestamp('2023-01-01 12:00:00')]  # Normal timestamp\n",
    "}\n",
    "\n",
    "new_df_ambiguous = pd.DataFrame(ambiguous_new_data)\n",
    "\n",
    "# Combine the new data point with the existing data\n",
    "df_combined = pd.concat([df, new_df_ambiguous], ignore_index=True)\n",
    "\n",
    "# Preprocess the combined data\n",
    "X_combined = preprocessor.transform(df_combined)\n",
    "\n",
    "# Fit the LOF model to the combined data and predict\n",
    "y_pred_combined = lof.fit_predict(X_combined)\n",
    "new_data_prediction = y_pred_combined[-1]\n",
    "\n",
    "# Output the result\n",
    "print('Anomaly' if new_data_prediction == -1 else 'Normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal\n"
     ]
    }
   ],
   "source": [
    "# Example new data point representing a normal outbound connection\n",
    "normal_new_data = {\n",
    "    'pid': [1501],  # Random PID within normal range\n",
    "    'process_name': ['chrome.exe'],  # Normal process\n",
    "    'src_ip': ['192.168.1.100'],  # Source IP (system IP)\n",
    "    'src_port': [5000],  # A typical source port\n",
    "    'dst_ip': ['151.101.1.69'],  # A typical destination IP for chrome.exe\n",
    "    'dst_port': [80],  # A standard HTTP port\n",
    "    'duration': [1.5],  # Normal duration\n",
    "    'bytes_sent': [300],  # Normal data sent\n",
    "    'bytes_received': [400],  # Normal data received\n",
    "    'timestamp': [pd.Timestamp('2023-01-01 12:00:00')]  # Normal timestamp\n",
    "}\n",
    "\n",
    "new_df_normal = pd.DataFrame(normal_new_data)\n",
    "\n",
    "# Combine the new data point with the existing data\n",
    "df_combined = pd.concat([df, new_df_normal], ignore_index=True)\n",
    "\n",
    "# Preprocess the combined data\n",
    "X_combined = preprocessor.transform(df_combined)\n",
    "\n",
    "# Fit the LOF model to the combined data and predict\n",
    "y_pred_combined = lof.fit_predict(X_combined)\n",
    "new_data_prediction = y_pred_combined[-1]\n",
    "\n",
    "# Output the result\n",
    "print('Anomaly' if new_data_prediction == -1 else 'Normal')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
